
import streamlit as st
import pandas as pd
import psycopg2
import io
from datetime import datetime

# ============ Config ============
st.set_page_config(page_title="Upload Production", layout="wide")
st.title("üì§ Upload Production Record")

# ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å session ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
current_user = st.session_state.get("username", "")

# ============ DB ============
def get_connection():
    return psycopg2.connect(st.secrets["postgres"]["conn_str"])

# ============ Helper ============
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤-‡∏´‡∏•‡∏±‡∏á"""
    df = df.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]
    return df

def coerce_int(s):
    """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô int ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô 0"""
    return pd.to_numeric(s, errors="coerce").fillna(0).astype(int)

# ============ UI ============

uploaded_file = st.file_uploader("üìÇ Upload Excel File (.xlsx)", type=["xlsx"])

if not uploaded_file:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô log_date, shift, department, machine_name, part_no, plan_qty, actual_qty, defect_qty, remark, operator_name")
    st.stop()

try:
    xls = pd.ExcelFile(uploaded_file)
except Exception as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏î‡πâ: {e}")
    st.stop()

# ‡πÇ‡∏´‡∏•‡∏î Master
with get_connection() as conn:
    machine_df = pd.read_sql("SELECT id AS machine_id, machine_name FROM machine_list WHERE is_active = TRUE", conn)
    part_df = pd.read_sql("SELECT id AS part_id, part_no FROM part_master WHERE is_active = TRUE", conn)

all_rows = []

for sheet in xls.sheet_names:
    try:
        raw = pd.read_excel(xls, sheet_name=sheet)
        df = normalize_columns(raw)

        # ‡∏´‡∏≤ index ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå log_date ‡πÄ‡∏û‡∏∑‡πà‡∏≠ "‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß" ‡∏ã‡πâ‡∏≤‡∏¢‡∏°‡∏∑‡∏≠‡∏ó‡∏¥‡πâ‡∏á (‡∏Å‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÇ‡∏ô‡πâ‡∏ï‡∏≠‡∏¢‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
        if "log_date" in df.columns:
            start_idx = df.columns.get_loc("log_date")
            df = df.iloc[:, start_idx:]
        else:
            st.warning(f"‚ùå ‡∏ä‡∏µ‡∏ó '{sheet}' ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'log_date' ‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏µ‡∏ó‡∏ô‡∏µ‡πâ")
            continue

        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏°‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå
        for col in ["remark", "operator_name", "created_by"]:
            if col not in df.columns:
                df[col] = ""

        needed = ["log_date", "shift", "department", "machine_name", "part_no",
                  "plan_qty", "actual_qty", "defect_qty", "remark", "operator_name", "created_by"]

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô created_by, remark, operator_name ‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß)
        must_have = ["log_date", "shift", "department", "machine_name", "part_no"]
        missing = [c for c in must_have if c not in df.columns]
        if missing:
            st.warning(f"‚ö†Ô∏è ‡∏ä‡∏µ‡∏ó '{sheet}' ‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {missing} ‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏µ‡∏ó‡∏ô‡∏µ‡πâ")
            continue

        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à (‡∏ñ‡πâ‡∏≤‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß)
        df = df.reindex(columns=needed, fill_value="")

        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df["log_date"] = pd.to_datetime(df["log_date"], errors="coerce").dt.date
        df = df.dropna(subset=["log_date", "machine_name", "part_no"])

        # number columns
        df["plan_qty"] = coerce_int(df["plan_qty"])
        df["actual_qty"] = coerce_int(df["actual_qty"])
        df["defect_qty"] = coerce_int(df["defect_qty"])

        # created_by ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        df["created_by"] = df["created_by"].apply(lambda x: x if str(x).strip() != "" else current_user)

        # ‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        df["created_at"] = datetime.now()

        # map machine_id / part_id
        df = df.merge(machine_df, how="left", on="machine_name")
        df = df.merge(part_df, how="left", on="part_no")

        # ‡πÅ‡∏à‡πâ‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÅ‡∏°‡∏õ
        miss_m = df[df["machine_id"].isna()]
        miss_p = df[df["part_id"].isna()]
        if not miss_m.empty:
            st.warning(f"‚ö†Ô∏è ‡∏ä‡∏µ‡∏ó '{sheet}' ‡∏û‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö master: {sorted(miss_m['machine_name'].dropna().unique().tolist())}")
        if not miss_p.empty:
            st.warning(f"‚ö†Ô∏è ‡∏ä‡∏µ‡∏ó '{sheet}' ‡∏û‡∏ö Part No. ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö master: {sorted(miss_p['part_no'].dropna().unique().tolist())}")

        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÅ‡∏°‡∏õ‡πÑ‡∏î‡πâ
        df_ok = df.dropna(subset=["machine_id", "part_id"]).copy()

        all_rows.append(df_ok)

    except Exception as e:
        st.error(f"‚ùå ‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏µ‡∏ó '{sheet}' ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

if not all_rows:
    st.stop()

df_upload = pd.concat(all_rows, ignore_index=True)

st.subheader("üëÄ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
preview_cols = [
    "log_date", "shift", "department", "machine_name", "part_no",
    "plan_qty", "actual_qty", "defect_qty", "operator_name", "remark", "created_by"
]
st.dataframe(df_upload[preview_cols], use_container_width=True)

# ‡∏õ‡∏∏‡πà‡∏° Export Preview (optional)
buffer = io.BytesIO()
with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
    df_upload.to_excel(writer, index=False, sheet_name="upload_preview")
st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Excel)",
                   data=buffer.getvalue(),
                   file_name="upload_preview.xlsx",
                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

st.markdown("---")
if st.button("üì• Upload to Database", type="primary"):
    try:
        insert_sql = """
            INSERT INTO production_log (
                log_date, shift, department, machine_id, part_id,
                plan_qty, actual_qty, defect_qty,
                created_by, created_at, remark, operator_name
            ) VALUES (
                %(log_date)s, %(shift)s, %(department)s, %(machine_id)s, %(part_id)s,
                %(plan_qty)s, %(actual_qty)s, %(defect_qty)s,
                %(created_by)s, %(created_at)s, %(remark)s, %(operator_name)s
            )
        """

        records = df_upload[[
            "log_date", "shift", "department", "machine_id", "part_id",
            "plan_qty", "actual_qty", "defect_qty", "created_by", "created_at",
            "remark", "operator_name"
        ]].to_dict(orient="records")

        with get_connection() as conn:
            with conn.cursor() as cur:
                cur.executemany(insert_sql, records)
            conn.commit()

        st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {len(records)} ‡πÅ‡∏ñ‡∏ß")

    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")
